{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from tensorflow.keras import *\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensors and operations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tf.constant([[1., 2., 3.], [4., 5., 6.]]) # matrix"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-23 21:14:14.045169: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tf.constant(42) # scalar"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "t"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "t.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "t.dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Indexing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "t[:, 1:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "t[..., 1, tf.newaxis]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ops"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "t + 10"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tf.square(t)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "t @ tf.transpose(t)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using `keras.backend`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "K = backend\n",
    "K.square(K.transpose(t)) + 10"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### From/To NumPy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "tf.constant(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "t.numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "np.array(t)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "tf.square(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "np.square(t)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conflicting Types"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Strings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "tf.constant(b\"hello world\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tf.constant(\"café\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "u"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "tf.strings.length(b, unit=\"UTF8_CHAR\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "tf.strings.unicode_decode(b, \"UTF-8\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### String arrays"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "tf.strings.length(p, unit=\"UTF8_CHAR\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "r"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(r)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ragged tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(r[1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "print(r[1:3])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(tf.concat([r, r2], axis=0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "tf.strings.unicode_encode(r3, \"UTF-8\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=string, numpy=array([b'DEF', b'G', b'', b'HI'], dtype=object)>"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "r.to_tensor()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sparse tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "print(s)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "tf.sparse.to_dense(s)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "s2 = s * 2.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "try:\n",
    "    s3 = s + 1.\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]],\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(s5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-23 21:14:22.012137: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at sparse_to_dense_op.cc:136 : Invalid argument: indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.union(set1, set2))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 2,  3,  4,  5,  6,  7],\n",
       "       [ 0,  7,  9, 10,  0,  0]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "v.assign(2 * v)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "v[0, 1].assign(42)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "v[:, 2].assign([0., 1.])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tensor Arrays"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "array.read(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "array.stack()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "mean"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 3.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "variance"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.6666665, 8.666667 ], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom loss function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start by loading and preparing the California housing dataset. We first load it, then split it into a training set, a validation set and a test set, and finally we scale it:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full,\n",
    "                                                      random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss  = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "_, ax = plt.subplots(figsize=(6, 4), dpi=100)\n",
    "\n",
    "z = np.linspace(-4, 4, 200)\n",
    "ax.plot(z, huber_fn(0, z), \"b-\", lw=2, label=\"huber($z$)\")\n",
    "ax.plot(z, z**2 / 2, \"b:\", lw=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "ax.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "ax.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "ax.axis([-4, 4, 0, 4])\n",
    "ax.grid(1)\n",
    "ax.set(xlabel=\"$z$\", title=\"Huber loss\")\n",
    "ax.legend(fontsize='medium')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-23 21:14:33.727779: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 7s 12ms/step - loss: 1.0359 - mae: 1.4555 - val_loss: 0.2638 - val_mae: 0.5595\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2131 - mae: 0.5096 - val_loss: 0.2124 - val_mae: 0.4981\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f51d910>"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving/Loading Models with Custom Objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_loss.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_loss.h5\",\n",
    "                          custom_objects={\"huber_fn\": huber_fn})\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 6ms/step - loss: 0.2037 - mae: 0.4929 - val_loss: 0.2399 - val_mae: 0.5226\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.1969 - mae: 0.4840 - val_loss: 0.2015 - val_mae: 0.4837\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13fa081f0>"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    return huber_fn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 4ms/step - loss: 0.2127 - mae: 0.4808 - val_loss: 0.2069 - val_mae: 0.4636\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2107 - mae: 0.4751 - val_loss: 0.2279 - val_mae: 0.4799\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13faf9ca0>"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_loss_threshold_2.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.2086 - mae: 0.4735 - val_loss: 0.2271 - val_mae: 0.4739\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2056 - mae: 0.4698 - val_loss: 0.2034 - val_mae: 0.4549\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13fc90550>"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "class HuberLoss(losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.4707 - mae: 1.4560 - val_loss: 0.3355 - val_mae: 0.5586\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2555 - mae: 0.5304 - val_loss: 0.2367 - val_mae: 0.4962\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13fda26a0>"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_loss_class.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_loss_class.h5\",\n",
    "                          custom_objects={\"HuberLoss\": HuberLoss})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2348 - mae: 0.5011 - val_loss: 0.3192 - val_mae: 0.5205\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2248 - mae: 0.4906 - val_loss: 0.2508 - val_mae: 0.4811\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ff46640>"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "model.loss.threshold"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other Custom Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "def my_softplus(z):  # return value is just tf.nn.softplus(z)\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "\n",
    "def my_positive_weights(weights):  # return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0., tf.zeros_like(weights), weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "layer = layers.Dense(1,\n",
    "                     activation=my_softplus,\n",
    "                     kernel_initializer=my_glorot_initializer,\n",
    "                     kernel_regularizer=my_l1_regularizer,\n",
    "                     kernel_constraint=my_positive_weights)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1,\n",
    "                 activation=my_softplus,\n",
    "                 kernel_regularizer=my_l1_regularizer,\n",
    "                 kernel_constraint=my_positive_weights,\n",
    "                 kernel_initializer=my_glorot_initializer),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 2.3829 - mae: 1.1635 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.6299 - mae: 0.5410 - val_loss: 1.4399 - val_mae: 0.5137\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140056520>"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "model.save(\"data/103/my_model_with_many_custom_parts.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_many_custom_parts.h5\",\n",
    "                          custom_objects={\n",
    "                              \"my_l1_regularizer\": my_l1_regularizer,\n",
    "                              \"my_positive_weights\": my_positive_weights,\n",
    "                              \"my_glorot_initializer\": my_glorot_initializer,\n",
    "                              \"my_softplus\": my_softplus,\n",
    "                          })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "class MyL1Regularizer(regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1,\n",
    "                 activation=my_softplus,\n",
    "                 kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                 kernel_constraint=my_positive_weights,\n",
    "                 kernel_initializer=my_glorot_initializer),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 2.3829 - mae: 1.1635 - val_loss: 1.4154 - val_mae: 0.5607\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6299 - mae: 0.5410 - val_loss: 1.4399 - val_mae: 0.5137\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f5d2fd0>"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "model.save(\"data/103/my_model_with_many_custom_parts.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_many_custom_parts.h5\",\n",
    "                          custom_objects={\n",
    "                              \"MyL1Regularizer\": MyL1Regularizer,\n",
    "                              \"my_positive_weights\": my_positive_weights,\n",
    "                              \"my_glorot_initializer\": my_glorot_initializer,\n",
    "                              \"my_softplus\": my_softplus,\n",
    "                          })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.5903 - huber_fn: 1.5558\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8054 - huber_fn: 0.3095\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140265b50>"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: if you use the same function as the loss and a metric, you may be surprised to see different results. This is generally just due to floating point precision errors: even though the mathematical equations are equivalent, the operations are not run in the same order, which can lead to small differences. Moreover, when using sample weights, there's more than just precision errors:\n",
    "* the loss since the start of the epoch is the mean of all batch losses seen so far. Each batch loss is the sum of the weighted instance losses divided by the _batch size_ (not the sum of weights, so the batch loss is _not_ the weighted mean of the losses).\n",
    "* the metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing.\n",
    "\n",
    "If you do the math, you will find that loss = metric * mean of sample weights (plus some floating point precision error)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.1245 - huber_fn: 0.2515\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.1216 - huber_fn: 0.2473\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "history.history[\"loss\"][0], history.history[\"huber_fn\"][0] * sample_weight.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.11749888211488724, 0.11906597473445153)"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Streaming metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "precision = metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "precision.result()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "precision.variables"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "precision.reset_states()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a streaming metric:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "class HuberMetric(metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)  # handles base args (e.g., dtype)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "m = HuberMetric(2.)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.]]), tf.constant([[10.]])) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# total = total + (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count = count + 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]]))\n",
    "\n",
    "m.result()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "m.variables"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check that the `HuberMetric` class works well:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5182 - huber_metric: 1.5182\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2909 - huber_metric: 0.2909\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1404f52b0>"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_metric.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_metric.h5\",\n",
    "                          custom_objects={\n",
    "                              \"huber_fn\": create_huber(2.0),\n",
    "                              \"HuberMetric\": HuberMetric\n",
    "                          })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2350 - huber_metric: 0.2350\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2278 - huber_metric: 0.2278\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140667670>"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Warning**: In TF 2.2, tf.keras adds an extra first metric in `model.metrics` at position 0 (see [TF issue #38150](https://github.com/tensorflow/tensorflow/issues/38150)). This forces us to use `model.metrics[-1]` rather than `model.metrics[0]` to access the `HuberMetric`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "model.metrics[-1].threshold"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks like it works fine! More simply, we could have created the class like this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "class HuberMetric(metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"selu\",\n",
    "                 kernel_initializer=\"lecun_normal\",\n",
    "                 input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "model.compile(loss=losses.Huber(2.0),\n",
    "              optimizer=\"nadam\",\n",
    "              weighted_metrics=[HuberMetric(2.0)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32),\n",
    "                    y_train.astype(np.float32),\n",
    "                    epochs=2,\n",
    "                    sample_weight=sample_weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.7800 - HuberMetric: 1.5672\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.1462 - HuberMetric: 0.2939\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "history.history[\"loss\"][0], history.history[\"HuberMetric\"][0] * sample_weight.mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.44554394483566284, 0.44554404180100277)"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_metric_v2.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_metric_v2.h5\",\n",
    "                          custom_objects={\"HuberMetric\": HuberMetric})\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 3ms/step - loss: 0.2377 - HuberMetric: 0.2377\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2279 - HuberMetric: 0.2279\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140908130>"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "model.metrics[-1].threshold"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "exponential_layer = layers.Lambda(lambda x: tf.exp(x))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    layers.Dense(1),\n",
    "    exponential_layer\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1275 - val_loss: 0.4457\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4750 - val_loss: 0.3798\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.3548\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3905 - val_loss: 0.3464\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3784 - val_loss: 0.3449\n",
      "162/162 [==============================] - 0s 706us/step - loss: 0.3586\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.3586340546607971"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\",\n",
    "            shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(name=\"bias\",\n",
    "                                    shape=[self.units],\n",
    "                                    initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)  # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config, \"units\": self.units,\n",
    "            \"activation\": activations.serialize(self.activation)\n",
    "        }\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential(\n",
    "    [MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "     MyDense(1)])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 4.1268 - val_loss: 0.9472\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7086 - val_loss: 0.6219\n",
      "162/162 [==============================] - 0s 735us/step - loss: 0.5474\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5473727583885193"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# model.save(\"data/103/my_model_with_a_custom_layer.h5\")\n",
    "model = models.load_model(\"data/103/my_model_with_a_custom_layer.h5\",\n",
    "                          custom_objects={\"MyDense\": MyDense})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "class MyMultiLayer(layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape, \" X2.shape: \",\n",
    "              X2.shape)  # Debugging of custom layer\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "inputs1 = layers.Input(shape=[2])\n",
    "inputs2 = layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that the `call()` method receives symbolic inputs, whose shape is only partially specified (at this stage, we don't know the batch size, which is why the first dimension is `None`):\n",
    "\n",
    "We can also pass actual data to the custom layer. To test this, let's split each dataset's inputs into two parts, with four features each:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "# Printing the splitted data shapes\n",
    "X_train_scaled_A.shape, X_train_scaled_B.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((11610, 4), (11610, 4))"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now notice that the shapes are fully specified:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's build a more complete model using the functional API (this is just a toy example, don't expect awesome performance):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = layers.Input(shape=X_train_scaled_A.shape[-1])\n",
    "input_B = layers.Input(shape=X_train_scaled_B.shape[-1])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = layers.Dense(1)(concat)\n",
    "model = models.Model(inputs=[input_A, input_B], outputs=[output])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit((X_train_scaled_A, X_train_scaled_B),\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "360/363 [============================>.] - ETA: 0s - loss: 3.6138X1.shape:  (None, 4)  X2.shape:  (None, 4)\n",
      "363/363 [==============================] - 4s 4ms/step - loss: 3.5973 - val_loss: 1.3630\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0132 - val_loss: 0.9773\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x140c19bb0>"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's create a layer with a different behavior during training and testing:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "class AddGaussianNoise(layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's a simple model that uses this custom layer:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0),\n",
    "    layers.Dense(30, activation=\"selu\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.7869 - val_loss: 7.6082\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2375 - val_loss: 4.4597\n",
      "162/162 [==============================] - 0s 724us/step - loss: 0.7560\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7559615969657898"
      ]
     },
     "metadata": {},
     "execution_count": 136
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "X_new_scaled = X_test_scaled"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            layers.Dense(n_neurons,\n",
    "                         activation=\"elu\",\n",
    "                         kernel_initializer=\"he_normal\")\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "class ResidualRegressor(models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = layers.Dense(30,\n",
    "                                    activation=\"elu\",\n",
    "                                    kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 22.7478\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2735\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9791\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5908\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5546\n",
      "162/162 [==============================] - 0s 845us/step - loss: 0.6500\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# model.save(\"data/103/my_custom_model.ckpt\")\n",
    "model = models.load_model(\"data/103/my_custom_model.ckpt\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 0.9445\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6352\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5321\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4260\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4222\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We could have defined the model using the sequential API instead:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"), block1,\n",
    "    block1, block1, block1,\n",
    "    ResidualBlock(2, 30),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.5508\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5562\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6406\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3759\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3875\n",
      "162/162 [==============================] - 0s 803us/step - loss: 0.4852\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Losses and Metrics Based on Model Internals"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note**: due to an issue introduced in TF 2.2 ([#46858](https://github.com/tensorflow/tensorflow/issues/46858)), it is currently not possible to use `add_loss()` along with the `build()` method. So the following code differs from the book: I create the `reconstruct` layer in the constructor instead of the `build()` method. Unfortunately, this means that the number of units in this layer must be hard-coded (alternatively, it could be passed as an argument to the constructor)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "class ReconstructingRegressor(models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            layers.Dense(30,\n",
    "                         activation=\"selu\",\n",
    "                         kernel_initializer=\"lecun_normal\") for _ in range(5)\n",
    "        ]\n",
    "        self.out = layers.Dense(output_dim)\n",
    "        self.reconstruct = layers.Dense(8)  # workaround for TF issue #46858\n",
    "        self.reconstruction_mean = metrics.Mean(name=\"reconstruction_error\")\n",
    "\n",
    "    #Commented out due to TF issue #46858, see the note above\n",
    "    #def build(self, batch_input_shape):\n",
    "    #    n_inputs = batch_input_shape[-1]\n",
    "    #    self.reconstruct = layers.Dense(n_inputs)\n",
    "    #    super().build(batch_input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "y_pred = model.predict(X_test_scaled)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 1.6313 - reconstruction_error: 1.0474\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4536 - reconstruction_error: 0.4022\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing Gradients with Autodiff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "gradients"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A non-persistent GradientTape can only be used tocompute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # works now!\n",
    "del tape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "dz_dw1, dz_dw2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "gradients"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "gradients"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "del tape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "    \n",
    "hessians = [\n",
    "    hessian_tape.gradient(jacobian, [w1, w2]) for jacobian in jacobians\n",
    "]\n",
    "del hessian_tape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "jacobians"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "hessians"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=nan>]"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "tf.math.log(tf.exp(tf.constant(30., dtype=tf.float32)) + 1.)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30.0>"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "x = tf.Variable([100.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "@tf.custom_gradient\n",
    "def my_better_softplus(z):\n",
    "    exp = tf.exp(z)\n",
    "\n",
    "    def my_softplus_gradients(grad):\n",
    "        return grad / (1 + 1 / exp)\n",
    "\n",
    "    return tf.math.log(exp + 1), my_softplus_gradients"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "def my_better_softplus(z):\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "x = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_better_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>])"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Computing Gradients Using Autodiff"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "l2_reg = regularizers.l2(0.05)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Dense(30,\n",
    "                 activation=\"elu\",\n",
    "                 kernel_initializer=\"he_normal\",\n",
    "                 kernel_regularizer=l2_reg),\n",
    "    layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None):\n",
    "    metrics = \" - \".join(\n",
    "        [f\"{m.name}: {m.result():.4f}\" for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(f\"\\r{iteration}/{total} - \" + metrics, end=end)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "import time\n",
    "\n",
    "mean_loss = metrics.Mean(name=\"loss\")\n",
    "mean_square = metrics.Mean(name=\"mean_square\")\n",
    "\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50/50 - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A fancier version with a progress bar:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "progress_bar(3500, 10000, size=6)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' 3500/10000 [=>....]'"
      ]
     },
     "metadata": {},
     "execution_count": 174
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join(\n",
    "        [f\"{m.name}: {m.result():.4f}\" for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(f\"\\r{progress_bar(iteration, total)} - {metrics}\", end=end)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "mean_loss = metrics.Mean(name=\"loss\")\n",
    "mean_square = metrics.Mean(name=\"mean_square\")\n",
    "\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = optimizers.Nadam(lr=0.01)\n",
    "loss_fn = losses.mean_squared_error\n",
    "mean_loss = metrics.Mean()\n",
    "metrix = [metrics.MeanAbsoluteError()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrix:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrix:\n",
    "        metric.reset_states()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "11610/11610 [==============================] - mean: 1.3955 - mean_absolute_error: 0.5722\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6774 - mean_absolute_error: 0.5280\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6351 - mean_absolute_error: 0.5177\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6384 - mean_absolute_error: 0.5181\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6440 - mean_absolute_error: 0.5222\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "    from collections import OrderedDict\n",
    "    with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1,\n",
    "                        n_steps + 1,\n",
    "                        desc=\"Epoch {}/{}\".format(epoch, n_epochs)) as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch)\n",
    "                        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(\n",
    "                        zip(gradients, model.trainable_variables))\n",
    "                    for variable in model.variables:\n",
    "                        if variable.constraint is not None:\n",
    "                            variable.assign(variable.constraint(variable))\n",
    "                    status = OrderedDict()\n",
    "                    mean_loss(loss)\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_states()\n",
    "except ImportError as ex:\n",
    "    print(\n",
    "        \"To run this cell, please install tqdm, ipywidgets and restart Jupyter\"\n",
    "    )\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "193ae7427fe140d3abdc76cbbb5977f7"
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56108386de284af8a36b4f45f550657f"
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f9f3ba84d4c463fb9ef4e2fedc4a4b3"
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4f6916d33b244a386663165c9606100"
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0681dfaf254a4889a1ae0d38ac663a84"
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2bf868a12514b57bb071281bba9d27a"
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TensorFlow Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "def cube(x):\n",
    "    return x ** 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "cube(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "cube(tf.constant(2.0))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x1412fe640>"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "tf_cube(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "source": [
    "tf_cube(tf.constant(2.0))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TF Functions and Concrete Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function.graph"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x14114d880>"
      ]
     },
     "metadata": {},
     "execution_count": 186
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "concrete_function(tf.constant(2.0))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "metadata": {},
     "execution_count": 187
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 188
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exploring Function Definitions and Graphs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "concrete_function.graph"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x14114d880>"
      ]
     },
     "metadata": {},
     "execution_count": 189
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "metadata": {},
     "execution_count": 191
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "pow_op.outputs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "source": [
    "concrete_function.function_def.signature"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name: \"__inference_cube_1064765\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### How TF Functions Trace Python Functions to Extract Their Computation Graphs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "source": [
    "@tf.function\n",
    "def tf_cube(x):\n",
    "    print(\"print:\", x)\n",
    "    return x ** 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "print: Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "result"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "result = tf_cube(2)\n",
    "result = tf_cube(3)\n",
    "result = tf_cube(tf.constant([[1., 2.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[3., 4.], [5., 6.]])) # New shape: trace!\n",
    "result = tf_cube(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # New shape: trace!"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "print: 2\n",
      "print: 3\n",
      "print: Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n",
      "print: Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x1409e43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "print: Tensor(\"x:0\", shape=(3, 2), dtype=float32)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function tf_cube at 0x1409e43a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is also possible to specify a particular input signature:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing\", images)\n",
    "    return images[:, ::2, ::2] # drop half the rows and columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "preprocessed_images = shrink(img_batch_2) # Reuses the same concrete function."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function shrink at 0x140fc9670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1xvuhggr.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function shrink at 0x140fc9670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: invalid syntax (tmp1xvuhggr.py, line 13)\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    preprocessed_images = shrink(img_batch_3)  # rejects unexpected types or shapes\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Autograph To Capture Control Flow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A \"static\" `for` loop using `range()`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "add_10(tf.constant(5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A \"dynamic\" loop using `tf.while_loop()`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    condition = lambda i, x: tf.less(i, 10)\n",
    "    body = lambda i, x: (tf.add(i, 1), tf.add(x, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "add_10(tf.constant(5))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "metadata": {},
     "execution_count": 207
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A \"dynamic\" `for` loop using `tf.range()` (captured by autograph):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Handling Variables and Other Resources in TF Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(counter, c=1):\n",
    "    return counter.assign_add(c)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "increment(counter)\n",
    "increment(counter)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "metadata": {},
     "execution_count": 212
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "metadata": {},
     "execution_count": 213
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "@tf.function\n",
    "def increment(c=1):\n",
    "    return counter.assign_add(c)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "increment()\n",
    "increment()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "metadata": {},
     "execution_count": 215
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c=1):\n",
    "        return self.counter.assign_add(c)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "@tf.function\n",
    "def add_10(x):\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "def tf__add(x):\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "def display_tf_code(func):\n",
    "    from IPython.display import display, Markdown\n",
    "    if hasattr(func, \"python_function\"):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown(f'```python\\n{code}\\n```'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "source": [
    "display_tf_code(add_10)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x):\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using TF Functions with tf.keras (or Not)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, tf.keras will automatically convert your custom code into TF Functions, no need to use\n",
    "`tf.function()`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "# Custom loss function\n",
    "def my_mse(y_true, y_pred):\n",
    "    print(\"Tracing loss my_mse()\")\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "# Custom metric function\n",
    "def my_mae(y_true, y_pred):\n",
    "    print(\"Tracing metric my_mae()\")\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "# Custom layer\n",
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(input_shape[1], self.units),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.biases = self.add_weight(name='bias',\n",
    "                                      shape=(self.units, ),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, X):\n",
    "        print(\"Tracing MyDense.call()\")\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Custom model\n",
    "class MyModel(models.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation=\"relu\")\n",
    "        self.hidden2 = MyDense(30, activation=\"relu\")\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input):\n",
    "        print(\"Tracing MyModel.call()\")\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = MyModel()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "model.fit(X_train_scaled,\n",
    "          y_train,\n",
    "          epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "342/363 [===========================>..] - ETA: 0s - loss: 2.8674 - my_mae: 1.2744Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 2s 2ms/step - loss: 2.7755 - my_mae: 1.2455 - val_loss: 0.5569 - val_my_mae: 0.4819\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4697 - my_mae: 0.4911 - val_loss: 0.4664 - val_my_mae: 0.4576\n",
      "162/162 [==============================] - 0s 893us/step - loss: 0.4164 - my_mae: 0.4639\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.4163525402545929, 0.4639028012752533]"
      ]
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can turn this off by creating the model with `dynamic=True` (or calling `super().__init__(dynamic=True, **kwargs)` in the model's constructor):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = MyModel(dynamic=True)\n",
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Not the custom code will be called at each iteration. Let's fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "model.fit(X_train_scaled[:64],\n",
    "          y_train[:64],\n",
    "          epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "          verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5.507260322570801, 2.0566811561584473]"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternatively, you can compile a model with `run_eagerly=True`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = MyModel()\n",
    "model.compile(loss=my_mse, optimizer=\"nadam\", metrics=[my_mae], run_eagerly=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "model.fit(X_train_scaled[:64],\n",
    "          y_train[:64],\n",
    "          epochs=1,\n",
    "          validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "          verbose=0)\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5.507260322570801, 2.0566811561584473]"
      ]
     },
     "metadata": {},
     "execution_count": 231
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Optimizers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining custom optimizers is not very common, but in case you are one of the happy few who gets to write one, here is an example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "class MyMomentumOptimizer(optimizers.Optimizer):\n",
    "    def __init__(self,\n",
    "                 learning_rate=0.001,\n",
    "                 momentum=0.9,\n",
    "                 name=\"MyMomentumOptimizer\",\n",
    "                 **kwargs):\n",
    "        \"\"\"Call super().__init__() and use _set_hyper() to store hyperparameters\"\"\"\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._set_hyper(\"learning_rate\",\n",
    "                        kwargs.get(\"lr\",\n",
    "                                   learning_rate))  # handle lr=learning_rate\n",
    "        self._set_hyper(\"decay\", self._initial_decay)  #\n",
    "        self._set_hyper(\"momentum\", momentum)\n",
    "\n",
    "    def _create_slots(self, var_list):\n",
    "        \"\"\"For each model variable, create the optimizer variable associated with it.\n",
    "        TensorFlow calls these optimizer variables \"slots\".\n",
    "        For momentum optimization, we need one momentum slot per model variable.\n",
    "        \"\"\"\n",
    "        for var in var_list:\n",
    "            self.add_slot(var, \"momentum\")\n",
    "\n",
    "    @tf.function\n",
    "    def _resource_apply_dense(self, grad, var):\n",
    "        \"\"\"Update the slots and perform one optimization step for one model variable\n",
    "        \"\"\"\n",
    "        var_dtype = var.dtype.base_dtype\n",
    "        lr_t = self._decayed_lr(var_dtype)  # handle learning rate decay\n",
    "        momentum_var = self.get_slot(var, \"momentum\")\n",
    "        momentum_hyper = self._get_hyper(\"momentum\", var_dtype)\n",
    "        momentum_var.assign(momentum_var * momentum_hyper -\n",
    "                            (1. - momentum_hyper) * grad)\n",
    "        var.assign_add(momentum_var * lr_t)\n",
    "\n",
    "    def _resource_apply_sparse(self, grad, var):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            \"learning_rate\":\n",
    "            self._serialize_hyperparameter(\"learning_rate\"),\n",
    "            \"decay\":\n",
    "            self._serialize_hyperparameter(\"decay\"),\n",
    "            \"momentum\":\n",
    "            self._serialize_hyperparameter(\"momentum\"),\n",
    "        }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss=\"mse\", optimizer=MyMomentumOptimizer())\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 905us/step - loss: 4.9648\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7888\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 918us/step - loss: 1.0021\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.7869\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 778us/step - loss: 0.7122\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1407c94f0>"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 12. Implement a custom layer that performs _Layer Normalization_\n",
    "_We will use this type of layer in Chapter 15 when using Recurrent Neural Networks._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a.\n",
    "_Exercise: The `build()` method should define two trainable weights *α* and *β*, both of shape `input_shape[-1:]` and data type `tf.float32`. *α* should be initialized with 1s, and *β* with 0s._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Solution: see below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b.\n",
    "_Exercise: The `call()` method should compute the mean_ μ _and standard deviation_ σ _of each instance's features. For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean μ and the variance σ<sup>2</sup> of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return *α*⊗(*X* - μ)/(σ + ε) + *β*, where ⊗ represents itemwise multiplication (`*`) and ε is a smoothing term (small constant to avoid division by zero, e.g., 0.001)._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "source": [
    "class LayerNormalization(layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\",\n",
    "                                     shape=batch_input_shape[-1:],\n",
    "                                     initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"beta\",\n",
    "                                    shape=batch_input_shape[-1:],\n",
    "                                    initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)  # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance +\n",
    "                                                  self.eps)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that making _ε_ a hyperparameter (`eps`) was not compulsory. Also note that it's preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of sqrt(z) is undefined when z=0, so training will bomb whenever the variance vector has at least one component equal to 0. Adding _ε_ within the square root guarantees that this will never happen."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c.\n",
    "_Exercise: Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(\n",
    "    losses.mean_absolute_error(keras_layer_norm(X), custom_layer_norm(X)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.6045884e-08>"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yep, that's close enough. To be extra sure, let's make alpha and beta completely random and compare again:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(\n",
    "    losses.mean_absolute_error(keras_layer_norm(X), custom_layer_norm(X)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.2921004e-08>"
      ]
     },
     "metadata": {},
     "execution_count": 236
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Still a negligeable difference! Our custom layer works fine."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 13. Train a model using a custom training loop to tackle the Fashion MNIST dataset\n",
    "_The Fashion MNIST dataset was introduced in Chapter 10._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### a.\n",
    "_Exercise: Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "source": [
    "(X_train_full, y_train_full), (X_test,\n",
    "                               y_test) = datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = optimizers.Nadam(lr=0.01)\n",
    "loss_fn = losses.sparse_categorical_crossentropy\n",
    "mean_loss = metrics.Mean()\n",
    "metrix = [metrics.SparseCategoricalAccuracy()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(\n",
    "                    zip(gradients, model.trainable_variables))\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrix:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(\n",
    "                metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrix:\n",
    "            metric.reset_states()\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b90adac3a66d4d7d8341e8fc17683451"
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bfdb22979624170981cc82821c5bba1"
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2213bbaf84b64d75b5d284f3981a706d"
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8b81ff355d7470dbc2b0a7ab3f91f17"
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7446b96bf7cb46f790bd645523ae4ff8"
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "984731c2d8da4d329931d93fddf39eb9"
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b.\n",
    "_Exercise: Try using a different optimizer with a different learning rate for the upper layers and the lower layers._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "lower_layers = models.Sequential([\n",
    "    layers.Flatten(input_shape=[28, 28]),\n",
    "    layers.Dense(100, activation=\"relu\"),\n",
    "])\n",
    "\n",
    "upper_layers = models.Sequential([\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model = models.Sequential([lower_layers, upper_layers])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "lower_optimizer = optimizers.SGD(lr=1e-4)\n",
    "upper_optimizer = optimizers.Nadam(lr=1e-3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = losses.sparse_categorical_crossentropy\n",
    "mean_loss = metrics.Mean()\n",
    "metrix = [metrics.SparseCategoricalAccuracy()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "source": [
    "with trange(1, n_epochs + 1, desc=\"All epochs\") as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in ((lower_layers, lower_optimizer),\n",
    "                                          (upper_layers, upper_optimizer)):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(\n",
    "                        zip(gradients, layers.trainable_variables))\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status[\"loss\"] = mean_loss.result().numpy()\n",
    "                for metric in metrix:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status[\"val_loss\"] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status[\"val_accuracy\"] = np.mean(\n",
    "                metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred))\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrix:\n",
    "            metric.reset_states()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cebc2fa2dfb2420089f2b9b8620dd4f2"
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a987f9c83c8f4ea5a734ca6e8b0bdd2e"
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21a84ffe5d1049269d380010242e9ec4"
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "512be8fe2f264f9fae1fe62fc505a340"
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "145011bb4ff14859af1ddd94f518a1a7"
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3639dc0ec954460861efcb48e3a9cfe"
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('kaggle': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "interpreter": {
   "hash": "14395c271f7a23b331c8f5f0139dc82129d4ff410a5b00cf69b55a03a150d670"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}